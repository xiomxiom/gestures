{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras_video import VideoFrameGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, GRU, Dense, Dropout,Conv2D, BatchNormalization,MaxPool2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "# from tensorflow.python.keras.engine.training import Model\n",
    "\n",
    "seed =88\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sub directories names as classes\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('D://gitcourse//videos/*')]\n",
    "classes.sort()\n",
    "\n",
    "# some global params\n",
    "SIZE = (128, 128)\n",
    "CHANNELS = 3\n",
    "NBFRAME = 20\n",
    "BS = 32\n",
    "\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='D:\\\\gitcourse\\\\videos\\\\{classname}\\\\*.avi'\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=False,\n",
    "#     rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split_val=.33, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e08d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convnet(shape=(SIZE[0], SIZE[0], CHANNELS)):\n",
    "    momentum = .9\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), input_shape=shape,\n",
    "        padding='same', activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    \n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "\n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model\n",
    "\n",
    "def action_model(shape=(NBFRAME, SIZE[0], SIZE[0], CHANNELS), nbout=3):\n",
    "\n",
    "    convnet = build_convnet(shape[1:])    \n",
    "    # final model\n",
    "    model = Sequential()\n",
    "    # add the convnet \n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "        \n",
    "    model.add(GRU(\n",
    "                  units=128,\n",
    "                  activation='tanh',\n",
    "                  recurrent_activation = 'sigmoid',\n",
    "                  recurrent_dropout=0.0,\n",
    "                  unroll=False,\n",
    "                  use_bias =True,\n",
    "                  reset_after =True,\n",
    "                 \n",
    "                 ))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556693c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) \n",
    "model = action_model(INSHAPE, len(classes))\n",
    "optimizer = Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cdfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=30\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(0,30)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
    "plt.plot(loss_train)\n",
    "plt.plot(loss_val)\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = history.history['acc']\n",
    "acc_val = history.history['val_acc']\n",
    "epochs = range(0,30)\n",
    "plt.plot( acc_train, 'g', label='Training accuracy')\n",
    "plt.plot( acc_val, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate_generator(train)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703efefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate_generator(valid)\n",
    "valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c335474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
